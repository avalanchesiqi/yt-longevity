import numpy as np
import matplotlib.pyplot as plt
from sklearn import model_selection, neighbors, metrics, linear_model

data1 = '206,142.7350,69.2888	218,152.3611,69.8904	191,118.5239,62.0544	333,95.6839,28.7339	244,173.0404,70.9182	276,218.8870,79.3069	244,167.2921,68.5623	236,169.9852,72.0276	200,132.7977,66.3988	218,132.9215,60.9732	244,168.9654,69.2481	218,69.5113,31.8859	239,174.8101,73.1423	245,189.2433,77.2421	358,93.3225,26.0677	230,157.7979,68.6078	282,208.5187,73.9428	264,182.0759,68.9681	188,157.1057,83.5669	235,144.6412,61.5494	207,152.4799,73.6618	417,122.7307,29.4318	353,96.1090,27.2263	280,94.3291,33.6890	269,77.5708,28.8367	259,99.6365,38.4697	120,79.3032,66.0860	247,204.5359,82.8080	226,180.4728,79.8552	203,167.5881,82.5557	244,194.0471,79.5275	192,165.1927,86.0379	210,174.5873,83.1368	238,198.1134,83.2409 246,189.6671,77.1004	255,211.0222,82.7538	241,179.3775,74.4305	243,199.6765,82.1714	250,199.8487,79.9395	219,188.2849,85.9748	191,165.9431,86.8812	183,158.5765,86.6538	241,197.3837,81.9019	171,134.2657,78.5180	311,239.4831,77.0042	245,203.8686,83.2117	247,157.7982,63.8859	152,112.2247,73.8320	246,205.8086,83.6620	183,158.3553,86.5330	278,225.8858,81.2539	258,133.0728,51.5786'
data2 = '121,76.9443,63.5904     203,89.7019,44.1881     226,111.8779,49.5035    326,154.7495,47.4692    91,67.5328,74.2119      273,112.8604,41.3408    219,165.9335,75.7687    347,145.4889,41.9276    260,129.8876,49.9568    408,221.1149,54.1948    265,131.6684,49.6862    223,146.7422,65.8037    356,180.0620,50.5792    319,147.2280,46.1530    272,217.0307,79.7907    211,141.9088,67.2554    214,95.5379,44.6439     298,165.7933,55.6353    260,154.3487,59.3649    325,155.8325,47.9485    628,280.6094,44.6830    270,120.8377,44.7547    238,130.1712,54.6938    255,161.6966,63.4104    285,187.8025,65.8956    270,150.0219,55.5637    293,189.6648,64.7320    211,157.6384,74.7102    321,200.9798,62.6105    230,167.8787,72.9907    312,204.0831,65.4113    267,180.3446,67.5448    265,180.1624,67.9858    311,210.7608,67.7687    207,161.6974,78.1147    206,152.2584,73.9119    325,205.2464,63.1527    343,249.5656,72.7597    272,198.4562,72.9618    440,320.4510,72.8298    288,219.9609,76.3753    194,150.3588,77.5045    190,129.6720,68.2484    232,135.0049,58.1918    343,159.2199,46.4198    215,143.1564,66.5844    227,151.0287,66.5325    224,152.4196,68.0445    211,137.9118,65.3611    339,198.3996,58.5249    275,166.8537,60.6741    248,194.1562,78.2888    241,149.9801,62.2324    422,272.1158,64.4824    321,142.7931,44.4838    648,329.2721,50.8136    267,183.1002,68.5769    213,152.3147,71.5092    1155,306.2894,26.5186   268,206.1464,76.9203    227,178.7949,78.7643    218,128.5218,58.9550    254,175.2683,69.0033    1067,410.8546,38.5056   269,189.0606,70.2827    360,163.7051,45.4736    246,151.4890,61.5809    235,151.6140,64.5166    555,274.3843,49.4386    317,167.6589,52.8892    182,120.4126,66.1608    211,152.3774,72.2168    208,134.1517,64.4960    169,119.4148,70.6597    538,275.4028,51.1901    286,158.4510,55.4025    233,137.6499,59.0772    344,210.5009,61.1921    269,199.9375,74.3262    252,143.6396,56.9999    210,138.4479,65.9275    230,182.9813,79.5571    467,236.0024,50.5359    388,168.1232,43.3307    257,145.4781,56.6063    278,162.9612,58.6191    508,275.7860,54.2886    255,181.5091,71.1800    169,106.2775,62.8861    240,131.4111,54.7546    260,137.2415,52.7852    1033,339.4284,32.8585   603,258.1084,42.8040    210,127.0761,60.5124    265,168.8088,63.7014    231,106.9599,46.3030    379,146.4743,38.6476    199,123.4436,62.0319    232,168.8827,72.7943    268,206.5574,77.0737    255,145.9100,57.2196    335,178.2617,53.2124    233,161.7451,69.4185    273,142.1274,52.0613    242,144.8143,59.8406    398,198.8499,49.9623    240,185.7321,77.3884    243,166.5041,68.5202    230,133.4400,58.0174    217,160.2971,73.8696    214,140.8057,65.7970    306,159.8826,52.2492    222,132.1458,59.5251    349,179.2666,51.3658    110,72.0857,65.5324     319,193.8634,60.7722    225,115.4452,51.3090    216,142.8886,66.1521    203,139.1841,68.5636    321,124.6577,38.8342    208,111.5004,53.6059    260,154.6209,59.4696    240,162.5099,67.7125    333,162.9910,48.9462    205,146.6464,71.5348    213,123.8632,58.1517    333,154.3565,46.3533    272,180.0458,66.1933    279,185.0975,66.3432    353,160.1741,45.3751    103,69.0398,67.0289     152,63.7935,41.9694     282,160.7376,56.9992    103,70.4489,68.3970     200,105.0738,52.5369    215,106.0661,49.3331    299,167.6332,56.0646    238,157.9344,66.3590    258,129.0387,50.0150    297,151.2848,50.9377    307,117.6544,38.3239    198,91.0177,45.9685'
data3 = '238,117.2381,49.2597    212,111.7850,52.7288    172,113.7144,66.1130    196,130.3191,66.4893    224,143.1390,63.9013    201,131.8453,65.5947    205,110.2217,53.7667    233,141.1784,60.5916    186,107.2182,57.6442    236,150.0251,63.5700    219,134.6186,61.4697    223,138.3825,62.0549    219,122.4711,55.9229'


def work(data, idx):
    duration, wt, wp = np.array(map(lambda x: x.split(','), data.split())).T

    duration = duration.astype('int').reshape(-1, 1)
    wt = wt.astype('float').reshape(-1, 1)
    wp = wp.astype('float').reshape(-1, 1)
    T = np.linspace(np.min(duration, 0), np.max(duration, 0), 250)[:, np.newaxis]

    weights = 'distance'

    ax1 = fig.add_subplot(321 + 2*idx)
    ax2 = fig.add_subplot(322 + 2*idx)

    ax1.scatter(duration, wt, c='k', s=10, label='data')
    ax1.set_xlabel('Video Duration')
    ax1.set_ylabel('Avg Watch Time')

    n_neighbors = 5
    knn_initializer = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)
    knn_model = knn_initializer.fit(duration, wt)
    wt_hat = knn_model.predict(T)
    ax1.plot(T, wt_hat, c='g', label='knn@{0}'.format(n_neighbors))
    plt.legend(loc='best')

    kf = model_selection.KFold(n_splits=5)

    # select best neighbors number
    best_err = np.inf
    best_neighbors_num = None
    m = int(0.8*duration.shape[0])
    for n_neighbors in xrange(1, m):
        error_list = []
        for train_index, test_index in kf.split(duration):
            X_train, X_test = duration[train_index], duration[test_index]
            y_train, y_test = wp[train_index], wp[test_index]

            knn_initializer = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)
            knn_model = knn_initializer.fit(X_train, y_train)
            y_hat = knn_model.predict(X_test)
            error_list.append(metrics.mean_absolute_error(y_test, y_hat))
        tot_err = np.sum(error_list)
        if tot_err < best_err:
            best_err = tot_err
            best_neighbors_num = n_neighbors

    knn_initializer = neighbors.KNeighborsRegressor(best_neighbors_num, weights=weights)
    knn_model = knn_initializer.fit(duration, wp)
    y_hat = knn_model.predict(duration)
    y_ = knn_model.predict(T)
    print 'mean absolute error knn: {0} at best neighbors {1}'.format(metrics.mean_absolute_error(wp, y_hat), best_neighbors_num)

    # linear regression model
    linreg = linear_model.Ridge().fit(duration, wp)
    y__ = linreg.predict(T)
    print 'mean absolute error ridge: ', metrics.mean_absolute_error(wp, linreg.predict(duration))

    ax2.scatter(duration, wp, c='k', s=10, label='data')
    # plt.scatter(X_test, y_test, c='r', marker='x', label='test data')
    ax2.plot(T, y_, c='g', label='knn@{0}'.format(best_neighbors_num))
    ax2.plot(T, y__, '--', c='b', label='linreg')
    ax2.set_ylim([0, 100])
    ax2.set_xlabel('Video Duration')
    ax2.set_ylabel('Avg Watch Percentage')
    plt.legend(loc='best')
    # plt.title('KNNeighborsRegressor (k = {0}, weights = {1})'.format(best_neighbors_num, weights))


if __name__ == '__main__':
    fig = plt.figure(figsize=(10, 10))
    for idx, data in enumerate([data1, data2, data3]):
        work(data, idx)
    plt.tight_layout()
    plt.show()
